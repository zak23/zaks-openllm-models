"mistral:7b-capybara-fp16":
  project: vllm-chat
  service_config:
    name: capybarahermes2_5
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-rtx-3090
  engine_config:
    model: argilla/CapybaraHermes-2.5-Mistral-7B
    max_model_len: 28704
    enforce_eager: true
    dtype: half
  extra_labels:
    openllm_alias: 7b
    model_name: argilla/CapybaraHermes-2.5-Mistral-7Bv0.1
  max_tokens:
    default: 28704
    maximum: 28704
    minimum: 128
    title: Max Tokens
    type: integer
"mistral:12b-dolphin-fp16":
  project: vllm-chat
  service_config:
    name: dolphin2_9_3
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-rtx-3090
  engine_config:
    model: cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b
    max_model_len: 20480
    enforce_eager: true
    dtype: half
  extra_labels:
    openllm_alias: 12b
    model_name: cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b
  max_tokens:
  default: 20480
  maximum: 20480
  minimum: 128
  title: Max Tokens
  type: integer
"mistral:7b-dolphin-bf16":
  project: vllm-chat
  service_config:
    name: dolphin2_9_3
    workers: 2
    traffic:
      timeout: 300
    resources:
      gpu: 2
      gpu_type: nvidia-rtx-3090
  engine_config:
    model: cognitivecomputations/dolphin-2.9.3-mistral-7B-32k
    max_model_len: 28704
    enforce_eager: true
    dtype: half
  extra_labels:
    openllm_alias: 7b
    model_name: cognitivecomputations/dolphin-2.9.3-mistral-7B-32k
  max_tokens:
  default: 28704
  maximum: 28704
  minimum: 128
  title: Max Tokens
  type: integer
"qwen2:7b-instruct-awq-4bit":
  project: vllm-chat
  service_config:
    name: qwen2
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-rtx-3060
  engine_config:
    model: Qwen/Qwen2-7B-Instruct-AWQ
    max_model_len: 2048
    quantization: awq
  extra_labels:
    openllm_alias: 7b-4bit,7b-instruct-4bit
    model_name: Qwen/Qwen2-7B-Instruct-AWQ
"qwen2:7b-instruct-fp16":
  project: vllm-chat
  service_config:
    name: qwen2
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-tesla-l4
  engine_config:
    model: Qwen/Qwen2-7B-Instruct
    max_model_len: 2048
    dtype: half
  extra_labels:
    openllm_alias: 7b,7b-instruct
    model_name: Qwen/Qwen2-7B-Instruct